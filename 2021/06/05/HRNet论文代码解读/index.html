<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="HRNet论文代码解读  前情提要好记性不如烂笔头！ 介绍 以前相关工作  对于人体姿态估计这种 position-sensitive 位置敏感任务，以往的方法大多参考经典的分类网络：先降低分辨率提取丰富语义低分辨率表征，再恢复高分辨率，找到对应的位置信息。  这种恢复分辨率的方法其实无法真正获取足够有效的高分辨率位置信息。  新的方法（总览）  HRNet提出一种新的特征提取方法，创新之处在于要">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/2021/06/05/HRNet%E8%AE%BA%E6%96%87%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="HRNet论文代码解读  前情提要好记性不如烂笔头！ 介绍 以前相关工作  对于人体姿态估计这种 position-sensitive 位置敏感任务，以往的方法大多参考经典的分类网络：先降低分辨率提取丰富语义低分辨率表征，再恢复高分辨率，找到对应的位置信息。  这种恢复分辨率的方法其实无法真正获取足够有效的高分辨率位置信息。  新的方法（总览）  HRNet提出一种新的特征提取方法，创新之处在于要">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2021/03/04/1ZDGBHJf7NjwQct.png">
<meta property="og:image" content="https://i.loli.net/2021/02/01/1eS2UdY8qKM4zZD.png">
<meta property="og:image" content="https://i.loli.net/2021/02/01/1yC8SZMWvxPelpf.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/rqGjR4XcAFgpDM8.png">
<meta property="og:image" content="https://i.loli.net/2021/03/01/DZoji7YTfBEqU4z.png">
<meta property="og:image" content="https://i.loli.net/2021/02/01/3IHdZJPVgiwN6oE.png">
<meta property="og:image" content="https://i.loli.net/2021/02/01/HFtvR4BD76NSwam.png">
<meta property="og:image" content="https://i.loli.net/2021/03/01/nJmIDfTCo9GbtWZ.png">
<meta property="og:image" content="https://i.loli.net/2021/02/01/4b7zFopNl6hEwuY.png">
<meta property="og:image" content="https://i.loli.net/2021/02/01/I26L5o9aNYdxj7i.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/MEPrl1ztbgi3DAY.png">
<meta property="og:image" content="https://i.loli.net/2021/03/01/ui65T7jnXLgM4we.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/fyJGKZ82uIa4ULq.png">
<meta property="og:image" content="https://i.loli.net/2021/02/02/92ojyRCLudlMPxt.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/fyJGKZ82uIa4ULq.png">
<meta property="og:image" content="https://i.loli.net/2021/02/02/AtFegN3siH4GM6c.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/DeQNmJIX4KhW6lO.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/fyJGKZ82uIa4ULq.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/5vB728zHsTUrDhw.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/sKxUNRG8wrW5Hgz.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/okZzfPjE54ugHWs.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/mySIXdc7p8qtWGw.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/9cZT2oxa5qU6rBY.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/avjNRznZhLTM5El.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/dlMFt6cJhnHzBWx.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/kdRxyf5WMrSusVz.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/EJdln43tSbiuAZ9.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/ntRmpkUTLVlJN61.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/Yj3xePFgW9V6hLH.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/azgCyUtunIdAf4V.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/VxWO8tTJvMKnojL.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/l2VyBLTG9uUd7Z8.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/YRO7U358I9EhLKt.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/gXVTbxZvaq2NG7u.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/jSshiqFrWtf83nM.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/cL6AXVGu4qWNm1j.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/BVLye1h3jnWc8Oo.png">
<meta property="og:image" content="https://i.loli.net/2021/03/04/8HVLqjetU5nNi3X.png">
<meta property="og:image" content="c:/Users/yeemi/AppData/Roaming/Typora/typora-user-images/image-20210304172144091.png">
<meta property="article:published_time" content="2021-06-05T12:03:14.132Z">
<meta property="article:modified_time" content="2021-03-04T12:49:25.426Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/03/04/1ZDGBHJf7NjwQct.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-HRNet论文代码解读" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/06/05/HRNet%E8%AE%BA%E6%96%87%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/" class="article-date">
  <time class="dt-published" datetime="2021-06-05T12:03:14.132Z" itemprop="datePublished">2021-06-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>HRNet论文代码解读</p>
<p><img src="https://i.loli.net/2021/03/04/1ZDGBHJf7NjwQct.png" alt="image-20210304095050167"></p>
<h1 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h1><p>好记性不如烂笔头！</p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><ul>
<li><strong>以前相关工作</strong></li>
</ul>
<p>对于人体姿态估计这种 <strong>position-sensitive 位置敏感</strong>任务，以往的方法大多参考经典的分类网络：先降低分辨率提取丰富语义低分辨率表征，再恢复高分辨率，找到对应的位置信息。</p>
<p><img src="https://i.loli.net/2021/02/01/1eS2UdY8qKM4zZD.png" alt="image-20210201113203997"></p>
<p>这种恢复分辨率的方法其实无法真正获取足够有效的高分辨率位置信息。</p>
<ul>
<li><strong>新的方法（总览）</strong></li>
</ul>
<p>HRNet提出一种新的特征提取方法，创新之处在于要从头到尾 <strong>维持</strong> 一条高分辨率表征分支。</p>
<p>HRNet 整体采用 <strong>并行</strong> 结构，共分为4个阶段。</p>
<p>第1阶段是1个高分辨率的子网络，此后逐步添加 <strong>由高到低</strong> 的分辨率子网络来组成新的阶段；第2阶段2种分辨率，第3阶段3种分辨率，以此类推。然后在不同阶段的多种分辨率之间，采用 <strong>多尺度融合</strong> 来交换信息。最后在网络的高分辨率输出上预测 keypoints 关键点。</p>
<p><img src="https://i.loli.net/2021/02/01/1yC8SZMWvxPelpf.png" alt="image-20210201113128108"></p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>（多人姿态估计）</p>
<p>HRNet 最初是在 top-down 流派下设计的，为了提升关键点检测准确率。</p>
<p>但是 HRNet 作为一种特征提取网络，其实是没有流派区别的，既可以用在 top-down ，也可以用在 bottom-up 上。</p>
<p><img src="https://i.loli.net/2021/03/04/rqGjR4XcAFgpDM8.png" alt="image-20210304110249244"></p>
<p>（上图为 top-down 流程，下图为 bottom-up 流程）</p>
<p>这里以 bottom-up 方法做示例。HRNet主要应用在 <strong>关键点检测模块</strong> 。</p>
<p><img src="https://i.loli.net/2021/03/01/DZoji7YTfBEqU4z.png" alt="image-20210301093723186"></p>
<h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>因为 HRNet 提出的方法主要应用在 <strong>关键点检测</strong> 上，所以下面的分析不放大到姿态估计的全貌，而是聚焦在关键点检测部分的特征提取部分。</p>
<p>为了方便我整个系列的进行，以后我们就叫他 <strong>backbone 骨干网络</strong> 。</p>
<p>backbone骨干网络的输入输出是这种形式：</p>
<ul>
<li><p>输入：feature maps 特征图（文中为1/4分辨率）</p>
</li>
<li><p>输出：feature maps 特征图（跟输入一致）</p>
</li>
</ul>
<p><img src="https://i.loli.net/2021/02/01/3IHdZJPVgiwN6oE.png" alt="image-20210201113128108"></p>
<h1 id="框架分析-High-Resolution-Network"><a href="#框架分析-High-Resolution-Network" class="headerlink" title="框架分析 High-Resolution Network"></a>框架分析 High-Resolution Network</h1><p>之前我们总览了整个网络，在这部分主要介绍论文里提出的重点方法，下一部分再通过实例化+代码解析的形式展现全貌。</p>
<p><strong>网络组成</strong></p>
<ul>
<li><strong>stem</strong>: 输入图片经过 由两个步幅为 2 的 $3*3$ 卷积组成的 Stem，将分辨率降低为原来的 $\frac{1}{4}$ ；<ul>
<li>输入 原图</li>
<li>输出 $\frac{1}{4}$ 分辨率特征图（同ResNet）</li>
</ul>
</li>
<li>==<strong>main body</strong>==: 包含 parallel multi-resolution convs., repeated multi-resolution fusions, representation head 等部分；<ul>
<li>输入  $\frac{1}{4}$ 分辨率特征图</li>
<li>输出  $\frac{1}{4}$ 分辨率特征图</li>
</ul>
</li>
</ul>
<p>接下来介绍在 main body 当中的重点部分！</p>
<h2 id="Parallel-Multi-Resolution-Convolutions"><a href="#Parallel-Multi-Resolution-Convolutions" class="headerlink" title="Parallel Multi-Resolution Convolutions."></a>Parallel Multi-Resolution Convolutions.</h2><p>并行的多分辨率卷积</p>
<p>HRNet 一共有4个 <strong>stage 阶段</strong>。这4个阶段远看符合常规的 <strong>high-to-low 由高到低</strong> 特征提取结构；但是每个阶段拥有不同分辨率的 stream（代码里对应的branch），新的阶段保留原有分辨率并新增加前一阶段的 $\frac{1}{2}$ 分辨率表征。（值得注意，为了保留信息，分辨率每降低一半，通道数翻倍。）</p>
<p>同时使用一种 <strong>parallel 并行</strong> 的结构将他们组合，类似这种：</p>
<p><img src="https://i.loli.net/2021/02/01/HFtvR4BD76NSwam.png" alt="image-20210201151445990"></p>
<p>（竖着看；下标的第一个数字代表阶段，第二个数字代表分辨率）</p>
<p><img src="https://i.loli.net/2021/03/01/nJmIDfTCo9GbtWZ.png" alt="image-20210301142754934"></p>
<p>简单地实例化一下网络，以 HRNet-w32 为例：</p>
<table>
<thead>
<tr>
<th>stage</th>
<th>resolution</th>
<th>channels</th>
</tr>
</thead>
<tbody><tr>
<td>stage1</td>
<td>$\frac{1}{4}$</td>
<td>32</td>
</tr>
<tr>
<td>stage2</td>
<td>$\frac{1}{4}$, $\frac{1}{8}$</td>
<td>64</td>
</tr>
<tr>
<td>stage3</td>
<td>$\frac{1}{4}$, $\frac{1}{8}$, $\frac{1}{16}$</td>
<td>128</td>
</tr>
<tr>
<td>stage4</td>
<td>$\frac{1}{4}$, $\frac{1}{8}$, $\frac{1}{16}$, $\frac{1}{32}$</td>
<td>256</td>
</tr>
</tbody></table>
<h2 id="Repeated-Multi-Resolution-Fusions"><a href="#Repeated-Multi-Resolution-Fusions" class="headerlink" title="Repeated Multi-Resolution Fusions."></a>Repeated Multi-Resolution Fusions.</h2><p>重复的多分辨率融合</p>
<p>不同阶段之间，使用重复的多尺度融合来进行信息交换。</p>
<p>交换阶段如图中的画圈部分：</p>
<p><img src="https://i.loli.net/2021/02/01/4b7zFopNl6hEwuY.png" alt="image-20210201184916954"></p>
<p>信息交换需要的操作，有两种：</p>
<ul>
<li><strong>下采样</strong>：使用步幅为2的 $3<em>3$ 卷积，分辨率下降2x；或者连续两个步幅为2的 $3</em>3$ 卷积，分辨率下降4x；</li>
<li><strong>上采样</strong>：用 nearest neighbor 上采样，后接 $1*1$ 卷积来统一通道数；</li>
</ul>
<p>(如上图)</p>
<ul>
<li>一般有两个情况，有多少个输入就有多少个输出（stage 4） or 输出比输入多一个$\frac{1}{2}$ 最低分辨率输出（stage 1, 2, 3）；</li>
<li>每个输出都要是前面所有输入的聚合；根据当前状态使用上、下采样操作或直接连接；</li>
</ul>
<p>以 3 种不同分辨率的 <strong>fusion 融合</strong> 为例：</p>
<p><img src="https://i.loli.net/2021/02/01/I26L5o9aNYdxj7i.png" alt="image-20210201234958059"></p>
<ul>
<li><p>输入：3种分辨率 ${R_r^i, r = 1, 2, 3}$</p>
</li>
<li><p>输出：3种分辨率 ${R_r^o, r = 1, 2, 3}$</p>
</li>
<li><p>$f_{xr}(·)$ fusion 函数，看人下菜碟，根据过来的分辨率和要输出的分辨率选择上、下采样或原样。</p>
</li>
<li><p>输出是输入经过分辨率变换后的<strong>相加</strong> $R_r^o = f_{1r}(R_1^i) + f_{2r}(R_2^i) + f_{3r}(R_3^i)$；</p>
</li>
<li><p>如果是跨阶段，比如stage3到stage4，就需要一个额外的输出，小 $\frac{1}{2}$ 分辨率。</p>
</li>
</ul>
<h2 id="Representation-Head"><a href="#Representation-Head" class="headerlink" title="Representation Head"></a>Representation Head</h2><p>表征头</p>
<p>涉及到输出阶段，取决于后续要应用到的任务，图示</p>
<p><img src="https://i.loli.net/2021/03/04/MEPrl1ztbgi3DAY.png" alt="image-20210304155708718"></p>
<p>分应用来说：</p>
<p><img src="https://i.loli.net/2021/03/01/ui65T7jnXLgM4we.png" alt="image-20210301143757662"></p>
<p>有三种，文中分别用来对应不同的任务。</p>
<ul>
<li><strong>HRNetV1</strong>: (a) 仅输出最高分辨率分支的表征。一般用于<strong>人体姿态估计</strong>。</li>
<li><strong>HRNetV2</strong>: (b) 直接通过双线性插值的上采样形式统一分辨率到最高，相连，后接 $1*1$ 卷积来混合表征。一般用于语义分割。</li>
<li><strong>HRNetV2p</strong>: (c) 将V2当中的输出，通过下采样操作分别采样到多个分辨率。一般用于目标检测。</li>
</ul>
<h2 id="实例化网络"><a href="#实例化网络" class="headerlink" title="实例化网络"></a>实例化网络</h2><p>文章参考 ResNet 的设计思路来分配每阶段的网络深度以及每种分辨率表征的通道数。</p>
<p><img src="https://i.loli.net/2021/03/04/fyJGKZ82uIa4ULq.png" alt="image-20210304155915801"></p>
<p>以 HRNet-W32 为例：</p>
<ul>
<li><p>4个 <strong>stage 阶段</strong>（括号里是分辨率）；</p>
<ul>
<li><p><strong>stage1</strong>：（$\frac{1}{4}$）4 residual units；每个unit 包含 1 <strong>bottleneck</strong> block（channels 64）；后接 $3*3$ 卷积将通道数减为  C=32 ;</p>
</li>
<li><p><strong>stage2</strong>：（$\frac{1}{8}$）1 <strong>modularized</strong> block；</p>
</li>
<li><p><strong>stage3</strong>：（$\frac{1}{16}$）4 <strong>modularized</strong> blocks；</p>
</li>
<li><p><strong>stage4</strong>：（$\frac{1}{32}$）3 <strong>modularized</strong> blocks；</p>
<ul>
<li><p>每个 <strong>modularized</strong> block 包含两部分：<strong>multi-resolution parallel convolutions</strong> 和 <strong>multi-resolution fusions</strong>;</p>
<p>  <img src="https://i.loli.net/2021/02/02/92ojyRCLudlMPxt.png" alt="image-20210202091503828"></p>
<ul>
<li>在 <strong>multi-resolution parallel convolutions</strong> 里的每个 <strong>branch</strong> 都有 4 个 residual units；</li>
<li>每个 units 包含 2 个 $3*3$ 卷积，后接 BN 和 ReLU；</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>4个 <strong>parallel subnetworks 并行子网络</strong>；</p>
<ul>
<li>子网络的 <strong>resolution 分辨率</strong> 减半的同时 <strong>channels 通道数</strong> 加倍；</li>
</ul>
</li>
</ul>
<p>单独梳理一下名词之间的关系：</p>
<ul>
<li>有4个 <strong>stage</strong>；<ul>
<li>每个 <strong>stage</strong> 由 <strong>modularized blocks</strong> 组成；modularized blocks 数量分别是 1，1，4，3 ；</li>
</ul>
</li>
<li>每个 <strong>modularized blocks</strong> 在 stage 1，2，3，4 分别有 1，2，3，4 个 <strong>branches</strong>; <ul>
<li>不同 <strong>branch</strong> 代表不同的分辨率；</li>
</ul>
</li>
<li>每个 <strong>branch</strong> 由 4 个 <strong>residual units</strong> 和 1 个 <strong>multi-resolution fusion unit</strong> 组成；</li>
</ul>
<p><img src="https://i.loli.net/2021/03/04/fyJGKZ82uIa4ULq.png" alt="image-20210304160723803"></p>
<p>用一个表格来表示：</p>
<p><img src="https://i.loli.net/2021/02/02/AtFegN3siH4GM6c.png" alt="image-20210202093400160"></p>
<p>表格当中，[·]是residual units，有 basic 版本和 bottleneck 版本；第二个数字表示 residual units 重复的次数；第三个数字表示 整个 modularized blocks 重复的次数；C 是 channels 通道数的意思。</p>
<p>按照 ResNet 的 PyTorch 实现流程，将其中 $7<em>7$ 卷积替换为2 个 $3</em>3$ 卷积；然后将分辨率降低为   $\frac{1}{4}$ 。</p>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmpose">mmpose</a></p>
<ul>
<li>configs</li>
<li>backbones</li>
<li><del>keypoints_head</del></li>
</ul>
<img src="https://i.loli.net/2021/03/04/DeQNmJIX4KhW6lO.png" alt="image-20210304171729648"  />













<h2 id="configs"><a href="#configs" class="headerlink" title="configs"></a>configs</h2><p>定位 <code>mmpose/configs/bottom_up/hrnet/coco/hrnet_w32_coco_512x512.py</code></p>
<p>整个configs文件可以分为以下几个大块：</p>
<ul>
<li>#runtime setting</li>
<li>#optimizer</li>
<li>#model setting</li>
</ul>
<h3 id="runtime-setting"><a href="#runtime-setting" class="headerlink" title="runtime setting"></a>runtime setting</h3><p>一些常规的设置，比如log，和加载checkpoints，工作流等等。</p>
<p><code>evaluation</code> 用来设定训练阶段的评价指标和检验的间隔。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># runtime setting</span></span><br><span class="line">log_level = <span class="string">&#x27;INFO&#x27;</span></span><br><span class="line">load_from = <span class="literal">None</span>  <span class="comment"># 给定路径，加载预训练模型；从头开始，不恢复训练。</span></span><br><span class="line">resume_from = <span class="literal">None</span>  <span class="comment"># 从上次保存好的checkpoints恢复训练。</span></span><br><span class="line">dist_params = <span class="built_in">dict</span>(backend=<span class="string">&#x27;nccl&#x27;</span>)  <span class="comment"># Parameters to setup distributed training, the port can also be set</span></span><br><span class="line">workflow = [(<span class="string">&#x27;train&#x27;</span>, <span class="number">1</span>)]  <span class="comment"># Workflow for runner. [(&#x27;train&#x27;, 1)] means there is only one workflow and the workflow named &#x27;train&#x27; is executed once</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Config to set the checkpoint hook, Refer to https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/checkpoint.py for implementation</span></span><br><span class="line">checkpoint_config = <span class="built_in">dict</span>(interval=<span class="number">50</span>)  <span class="comment"># 每隔多少interval保存一次checkpoints。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Config of evaluation during training</span></span><br><span class="line">evaluation = <span class="built_in">dict</span>(interval=<span class="number">50</span>, metric=<span class="string">&#x27;mAP&#x27;</span>, key_indicator=<span class="string">&#x27;AP&#x27;</span>)</span><br><span class="line"><span class="comment"># 训练期间：使用evaluation的间隔；哪种评价指标；以什么为关键指标来保存最佳checkpoint</span></span><br></pre></td></tr></table></figure>



<h3 id="optimizer"><a href="#optimizer" class="headerlink" title="optimizer"></a>optimizer</h3><p>一些关于优化器的配置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">optimizer = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">&#x27;Adam&#x27;</span>,</span><br><span class="line">    lr=<span class="number">0.0015</span>,</span><br><span class="line">)</span><br><span class="line">optimizer_config = <span class="built_in">dict</span>(grad_clip=<span class="literal">None</span>)  <span class="comment"># Do not use gradient clip</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># learning policy</span></span><br><span class="line">lr_config = <span class="built_in">dict</span>(</span><br><span class="line">    policy=<span class="string">&#x27;step&#x27;</span>,  <span class="comment"># Policy of scheduler</span></span><br><span class="line">    warmup=<span class="string">&#x27;linear&#x27;</span>,  <span class="comment"># Type of warmup used.</span></span><br><span class="line">    warmup_iters=<span class="number">500</span>,  <span class="comment"># The number of iterations or epochs that warmup</span></span><br><span class="line">    warmup_ratio=<span class="number">0.001</span>,  <span class="comment"># LR used at the beginning of warmup equals to warmup_ratio * initial_lr</span></span><br><span class="line">    step=[<span class="number">200</span>, <span class="number">260</span>])  <span class="comment"># Steps to decay the learning rate</span></span><br><span class="line">total_epochs = <span class="number">300</span>  <span class="comment"># Total epochs to train the model</span></span><br></pre></td></tr></table></figure>



<p>存放配置文件，这里主要看 <code># model setting</code> 部分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model settings</span></span><br><span class="line">model = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">&#x27;BottomUp&#x27;</span>,</span><br><span class="line">    pretrained=<span class="string">&#x27;https://download.openmmlab.com/mmpose/&#x27;</span></span><br><span class="line">    <span class="string">&#x27;pretrain_models/hrnet_w32-36af842e.pth&#x27;</span>,</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># backbone 来源 `mmpose/mmpose/models/backbones/hrnet.py`</span></span><br><span class="line">    backbone=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;HRNet&#x27;</span>,</span><br><span class="line">        in_channels=<span class="number">3</span>,</span><br><span class="line">        extra=<span class="built_in">dict</span>(</span><br><span class="line">            stage1=<span class="built_in">dict</span>(</span><br><span class="line">                num_modules=<span class="number">1</span>,</span><br><span class="line">                num_branches=<span class="number">1</span>,</span><br><span class="line">                block=<span class="string">&#x27;BOTTLENECK&#x27;</span>,</span><br><span class="line">                num_blocks=(<span class="number">4</span>, ),</span><br><span class="line">                num_channels=(<span class="number">64</span>, )),</span><br><span class="line">            stage2=<span class="built_in">dict</span>(</span><br><span class="line">                num_modules=<span class="number">1</span>,</span><br><span class="line">                num_branches=<span class="number">2</span>,</span><br><span class="line">                block=<span class="string">&#x27;BASIC&#x27;</span>,</span><br><span class="line">                num_blocks=(<span class="number">4</span>, <span class="number">4</span>),</span><br><span class="line">                num_channels=(<span class="number">32</span>, <span class="number">64</span>)),</span><br><span class="line">            stage3=<span class="built_in">dict</span>(</span><br><span class="line">                num_modules=<span class="number">4</span>,</span><br><span class="line">                num_branches=<span class="number">3</span>,</span><br><span class="line">                block=<span class="string">&#x27;BASIC&#x27;</span>,</span><br><span class="line">                num_blocks=(<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>),</span><br><span class="line">                num_channels=(<span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>)),</span><br><span class="line">            stage4=<span class="built_in">dict</span>(</span><br><span class="line">                num_modules=<span class="number">3</span>,</span><br><span class="line">                num_branches=<span class="number">4</span>,</span><br><span class="line">                block=<span class="string">&#x27;BASIC&#x27;</span>,</span><br><span class="line">                num_blocks=(<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>),</span><br><span class="line">                num_channels=(<span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>))),</span><br><span class="line">    ),</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<p>对应实例化！(hrnet_w32)</p>
<p><img src="https://i.loli.net/2021/03/04/fyJGKZ82uIa4ULq.png" alt="image-20210304161237390"></p>
<p><img src="https://i.loli.net/2021/03/04/5vB728zHsTUrDhw.png" alt="image-20210202093400160"></p>
<h2 id="backbones"><a href="#backbones" class="headerlink" title="backbones"></a>backbones</h2><p><img src="https://i.loli.net/2021/03/04/sKxUNRG8wrW5Hgz.png" alt="image-20210304100603427"></p>
<p>定位 <code>mmpose/configs/bottom_up/hrnet/coco/hrnet_w32_coco_512x512.py</code></p>
<h3 id="ResNet-块"><a href="#ResNet-块" class="headerlink" title="ResNet 块"></a>ResNet 块</h3><p><img src="https://i.loli.net/2021/03/04/okZzfPjE54ugHWs.png" alt="image-20210304100711857"></p>
<p><img src="https://i.loli.net/2021/03/04/mySIXdc7p8qtWGw.png" alt="img"></p>
<p>（左图是BasicBlock，右图是Bottleneck）</p>
<h3 id="HRModule"><a href="#HRModule" class="headerlink" title="HRModule"></a>HRModule</h3><p><img src="https://i.loli.net/2021/03/04/9cZT2oxa5qU6rBY.png" alt="image-20210304101056982"></p>
<ul>
<li><strong>分支模块</strong><ul>
<li>判断输入输出；</li>
<li>执行（循环）分支创建，每条分支内部分辨率相同；</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2021/03/04/avjNRznZhLTM5El.png" alt="image-20210304104722677"></p>
<p>以图为例，stage2 的分支的创建需要经过两步：</p>
<p>第一步，在 stage2 经过 <code>_check_barnches</code> 多出一条低分辨率分支，通过下一趴会提到的 <code>_make_transition_layer</code> 创建一个过渡的低分辨率分支；</p>
<p>第二步，<code>_make_one_branch</code>顺序搭建指定数目的 blocks；然后用 <code>_make_branches</code> 循环搭建；注意这里只有第一个block需要考虑升降维情况。</p>
<p><img src="https://i.loli.net/2021/03/04/dlMFt6cJhnHzBWx.png" alt="image-20210304104046076"></p>
<p>配置代码如下：</p>
<p><img src="https://i.loli.net/2021/03/04/kdRxyf5WMrSusVz.png" alt="image-20210304104134905"></p>
<ul>
<li><strong>融合模块</strong><ul>
<li>判断分支数，如果是1条分支，不用融合；</li>
<li>根据论文里的图示形式来融合分支；</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2021/03/04/EJdln43tSbiuAZ9.png" alt="image-20210304104928947"></p>
<p>以 stage2 为例，融合模块在这里：</p>
<p><img src="https://i.loli.net/2021/03/04/ntRmpkUTLVlJN61.png" alt="Snipaste_2021-03-04_10-45-41"></p>
<p>融合形式如下：</p>
<p><img src="https://i.loli.net/2021/03/04/Yj3xePFgW9V6hLH.png" alt="image-20210304104418713"></p>
<h3 id="HRNet"><a href="#HRNet" class="headerlink" title="HRNet"></a>HRNet</h3><p><img src="https://i.loli.net/2021/03/04/azgCyUtunIdAf4V.png" alt="image-20210304163334833"></p>
<ul>
<li><strong>创建过渡层</strong> <code>_make_transition_layer</code><ul>
<li>判断新的 stage 是否需要生成多一个</li>
<li>生成下一个 stage 的<strong>输入</strong>特征</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2021/03/04/VxWO8tTJvMKnojL.png" alt="image-20210304163237803"></p>
<ul>
<li><strong>创建层和阶段</strong> <code>_make_layer</code> <code>_make_stage</code><ul>
<li>利用HRModule里写的函数来做</li>
</ul>
</li>
</ul>
<h1 id="结果（HPE）"><a href="#结果（HPE）" class="headerlink" title="结果（HPE）"></a>结果（HPE）</h1><ul>
<li><strong>数据集上的结果</strong></li>
</ul>
<img src="https://i.loli.net/2021/03/04/l2VyBLTG9uUd7Z8.png" alt="image-20210304163745871" style="zoom:80%;" />

<img src="https://i.loli.net/2021/03/04/YRO7U358I9EhLKt.png" alt="image-20210304163835490" style="zoom:80%;" />





<ul>
<li><strong>mmpose版本，精度提升</strong></li>
</ul>
<p>（top-down）</p>
<img src="https://i.loli.net/2021/03/04/gXVTbxZvaq2NG7u.png" alt="image-20210304164524369" style="zoom: 50%;" />



<p>（bottom-up）</p>
<img src="https://i.loli.net/2021/03/04/jSshiqFrWtf83nM.png" alt="image-20210304164306266" style="zoom: 50%;" />





<ul>
<li><strong>内存和速度</strong></li>
</ul>
<p><img src="https://i.loli.net/2021/03/04/cL6AXVGu4qWNm1j.png" alt="image-20210304164140917"></p>
<img src="https://i.loli.net/2021/03/04/BVLye1h3jnWc8Oo.png" alt="image-20210304170832084" style="zoom:67%;" />







<ul>
<li><strong>消融实验 ablation study</strong></li>
</ul>
<img src="https://i.loli.net/2021/03/04/8HVLqjetU5nNi3X.png" alt="image-20210304172031937" style="zoom: 67%;" />

<img src="C:/Users/yeemi/AppData/Roaming/Typora/typora-user-images/image-20210304172144091.png" alt="image-20210304172144091" style="zoom:67%;" />









<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>源码</p>
<p><a target="_blank" rel="noopener" href="https://mmpose.readthedocs.io/en/latest/tutorials/0_config.html">https://mmpose.readthedocs.io/en/latest/tutorials/0_config.html</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmpose">https://github.com/open-mmlab/mmpose</a></p>
<p>博客</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/152594622">https://zhuanlan.zhihu.com/p/152594622</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_38715903/article/details/101629781">https://blog.csdn.net/weixin_38715903/article/details/101629781</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/pprp/p/12750692.html">https://www.cnblogs.com/pprp/p/12750692.html</a></p>
<p>论文</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.07919">https://arxiv.org/abs/1908.07919</a></p>
<p>Sun K, Xiao B, Liu D, et al. Deep high-resolution representation learning for human pose estimation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 5693-5703.</p>
<p>Wang J, Sun K, Cheng T, et al. Deep high-resolution representation learning for visual recognition[J]. IEEE transactions on pattern analysis and machine intelligence, 2020.</p>
<p>Cheng B, Xiao B, Wang J, et al. Higherhrnet: Scale-aware representation learning for bottom-up human pose estimation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 5386-5395.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/06/05/HRNet%E8%AE%BA%E6%96%87%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/" data-id="ckpjpkfre0001z8ukhx04gcex" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2021/06/05/hi/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">hi</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/06/05/HRNet%E8%AE%BA%E6%96%87%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/06/05/hi/">hi</a>
          </li>
        
          <li>
            <a href="/2021/06/05/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>